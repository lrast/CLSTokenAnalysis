{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf903719-0bf1-48b9-9e24-c02f8bd31dd0",
   "metadata": {},
   "source": [
    "# Running the experiments for all models.\n",
    "\n",
    "Different models need different experiments to characterize them, I may automate these decisions, but it's worth doing it manually at least once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fcd6c62-f38c-4258-bd9c-9bebc1050161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213b59fa-34b1-4a36-a237-25e5f5cb56d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Download dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d94230b5-fa7b-4691-8433-c89979e70604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d01b9c62a174c55bfe57b19aa14bdf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e9465e0ffa4aa9ad1596abf0dc27f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23f2ac76c7d47c69db5fa994e36dcac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc6ea5b5c9f434ea72cf0d548e806f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f421e8ae6dda4db1b89c7c9cac77091a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18932d8da4d241b795eabb561a3870f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f877036cd924de784dfb642ea2af5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/46 shards):   0%|          | 0/200000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5328b2c8348a45c3aa2783a11e7ba445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90cb77cc3f7492bbc887b10dd8395b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/14 shards):   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from initialization.download_datasubset import download_stratified_image_subsets \n",
    "base_dataset = \"ILSVRC/imagenet-1k\"\n",
    "\n",
    "download_stratified_image_subsets(base_dataset, splits=['train', 'validation'], split_mapping={'validation': 'test'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdab4e7-4ec0-4a01-ae8b-73e12d858c4a",
   "metadata": {},
   "source": [
    "## Experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c294136a-5dc5-432b-93f5-130860ffaebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0122 09:12:12.428000 39512 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n"
     ]
    }
   ],
   "source": [
    "from setup import image_model_setup\n",
    "from initialization.activity_dataset import generate_activity_dataset\n",
    "from analysis import run_across_layers, apply_model_decoder, accuracy_random_CLS,\\\n",
    "                     linear_probe_by_ridge_regression, model_accuracy\n",
    "from training import fit_probes_by_ridge_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e28328-4f85-440c-a42e-a5cd6306ee41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### google/vit-base-patch16-224\n",
    "\n",
    "The baseline case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d1e6588-a3fd-4264-8766-79e6dbc37731",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/vit-base-patch16-224\"\n",
    "dataset_name = \"temp_dataset_subsample\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18c6c8e-5116-4af2-bebe-6ecb1cc125f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b138f2422e48f5a7716b46ee534770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, image_datasets, _ = image_model_setup(model_name, dataset_name, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0791fd49-9c97-43f2-a054-1be1bbd87478",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5752563591004fbd832f444511e60c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0121 10:44:56.923000 6100 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 10:44:56.923000 6098 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 10:44:56.931000 6101 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 10:44:56.931000 6099 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "/Users/luke/.local/defaultPythonEnv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "/Users/luke/.local/defaultPythonEnv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb0126cca4648bca8eedbea1b47124a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0121 11:05:36.730000 29862 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 11:05:36.730000 29863 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 11:05:36.730000 29861 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 11:05:36.730000 29864 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42436426c8ca4241b2c5844edb11478b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/16 shards):   0%|          | 0/200000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684b0e1ce21c4b568a3799417ba12a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "activity_dataset = generate_activity_dataset(model, image_datasets,\n",
    "                                             include_classifier_inputs=True,\n",
    "                                             output_dir='temp_activity_dataset',\n",
    "                                             device='mps'\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7c4833-1175-43a0-b931-2c255e75d751",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]W0121 11:11:01.032000 29911 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 11:11:01.032000 29912 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 11:11:01.032000 29910 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 11:11:01.032000 29913 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "338it [04:08,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [04:46,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [04:47,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "acc = model_accuracy(model.model, image_datasets['test'], shuffle=None, device='mps', num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a869394-c063-475f-9cb3-7e7ac8e9b99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8027200102806091"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01c13f-ad2e-456b-b21b-c4d0b557756e",
   "metadata": {},
   "source": [
    "High accuracy to start with: no probe training needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed2d7bb9-1416-4e47-95d1-492c0489936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "probe_results = linear_probe_by_ridge_regression(activity_dataset, cvfold=5)\n",
    "all_results.append(probe_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d63ef37-fe7e-4460-8de5-26b89205d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_results = apply_model_decoder(model, activity_dataset)\n",
    "all_results.append(decoder_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1810c1ed-f30f-4daf-9511-717ab11aea32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“• Analysis: <function accuracy_random_CLS at 0x31ba2e520>\n",
      "ðŸ“„ Layer: vit.encoder.layer.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:04,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: vit.encoder.layer.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:59,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: vit.encoder.layer.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:02,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: vit.encoder.layer.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:02,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: vit.encoder.layer.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:58,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: vit.encoder.layer.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:58,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: vit.encoder.layer.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:57,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: vit.encoder.layer.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:58,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: vit.encoder.layer.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:58,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: vit.encoder.layer.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:55,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: vit.encoder.layer.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:53,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: vit.encoder.layer.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:53,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "randomization_results = run_across_layers(model, image_datasets,\n",
    "                                          accuracy_random_CLS,  shuffle=None,\n",
    "                                          device='mps')\n",
    "all_results.append(randomization_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae4f25bd-6d92-492e-85a7-eed4c28d6088",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(all_results).to_csv('results/cross_model_CLS_2/results_vit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b67e14-75bc-40d3-a6ee-12a0b5185ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b8a7882-ea4f-4ab9-884c-8943ddd770d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### facebook/deit-base-distilled-patch16-224\n",
    "\n",
    "Requires analysis with and without distillation tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d965d4-386c-4cd1-bd18-d9bd16ca341c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367f0f33cce8441a8feb1396195352ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"facebook/deit-base-distilled-patch16-224\"\n",
    "dataset_name = \"temp_dataset_subsample\"\n",
    "\n",
    "model, image_datasets, _ = image_model_setup(model_name, dataset_name, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8389a354-f231-4618-84ee-6f59ecd0c12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccbe622f6c94385a3bea9e58d2510ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0121 15:13:29.775000 31889 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 15:13:29.798000 31888 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 15:13:29.812000 31890 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 15:13:29.830000 31891 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "/Users/luke/.local/defaultPythonEnv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "/Users/luke/.local/defaultPythonEnv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ae6a9578fd47f2ae021569bb246669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0121 15:33:44.797000 32100 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 15:33:44.797000 32101 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 15:33:44.797000 32103 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 15:33:44.798000 32102 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad82b3936fb54e62aad04d4ced80dddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/16 shards):   0%|          | 0/200000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41aba2a5b46e4242bbe09317b2e89839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "activity_dataset = generate_activity_dataset(model, image_datasets,\n",
    "                                             include_classifier_inputs=True,\n",
    "                                             output_dir='temp_activity_dataset',\n",
    "                                             device='mps'\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f503e03-3117-45cc-b59c-2ab6abcce8fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]W0121 14:52:38.619000 31689 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 14:52:38.622000 31688 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 14:52:38.796000 31690 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 14:52:38.804000 31691 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "338it [03:51,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [04:31,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [04:32,  1.44it/s]\n",
      "0it [00:00, ?it/s]W0121 14:57:11.400000 31716 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 14:57:11.400000 31718 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 14:57:11.400000 31717 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 14:57:11.400000 31719 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "338it [04:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [04:40,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [04:41,  1.39it/s]\n",
      "0it [00:00, ?it/s]W0121 15:01:54.235000 31760 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 15:01:54.235000 31761 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 15:01:54.235000 31762 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 15:01:54.235000 31759 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "338it [04:11,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [04:53,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [04:54,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# double check accuracy and operation of the hook\n",
    "\n",
    "acc = model_accuracy(model.model, image_datasets['test'], shuffle=None, device='mps', num_workers=4)\n",
    "\n",
    "with model.zero_out_auxiliary_outputs():\n",
    "    acc_no_distillation = model_accuracy(model.model, image_datasets['test'], shuffle=None, device='mps', num_workers=4)\n",
    "\n",
    "acc_post = model_accuracy(model.model, image_datasets['test'], shuffle=None, device='mps', num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc47811-bc38-464b-ae29-ea2b31bb32da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83406001329422 0.8289600014686584 0.83406001329422\n"
     ]
    }
   ],
   "source": [
    "print(acc, acc_no_distillation, acc_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5bfd37-897d-4555-8589-24c38278353c",
   "metadata": {},
   "source": [
    "Looks good: zeroing out distillation tokens has an effect, but only a small one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc03283-1451-4cd5-95cd-0008de1229e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLS token probing is un-effected by distillation outputs\n",
    "all_results = []\n",
    "probe_results = linear_probe_by_ridge_regression(activity_dataset, cvfold=5)\n",
    "all_results.append(probe_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bac152f-3566-4268-b8d1-7241856e5c81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“• Analysis: <function accuracy_random_CLS at 0x324bb9d00>\n",
      "ðŸ“„ Layer: deit.encoder.layer.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:03,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:55,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:53,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:52,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:52,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:52,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:52,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:51,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:52,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:52,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:53,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:57,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "randomization_results = run_across_layers(model, image_datasets,\n",
    "                                          accuracy_random_CLS,  shuffle=None,\n",
    "                                          device='mps')\n",
    "all_results.append(randomization_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea17389-ba01-46c0-9fd9-283f28474ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“• Analysis: <function accuracy_random_CLS at 0x324bb9d00>\n",
      "ðŸ“„ Layer: deit.encoder.layer.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:57,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:55,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:56,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:58,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:58,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:59,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:57,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:58,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:58,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: deit.encoder.layer.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [06:58,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "with model.zero_out_auxiliary_outputs():\n",
    "    randomization_results = run_across_layers(model, image_datasets,\n",
    "                                              accuracy_random_CLS,  shuffle=None,\n",
    "                                              device='mps')\n",
    "\n",
    "randomization_results['distillation_disabled'] = True\n",
    "all_results.append(randomization_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa08d4a9-6c0f-49c8-a698-a997c4315011",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(all_results).to_csv('results/cross_model_CLS/results_deit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd94e4-27fd-4176-86b4-80cbf43fc47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00b24cdd-17e7-484c-967f-0ba03ae93ad9",
   "metadata": {},
   "source": [
    "### facebook/dinov2-base\n",
    "\n",
    "Requires probe training,  analysis with and without GAP outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e63760f-4ca6-46dc-a594-4e753035320b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f00bc6f71314b7a8553590cff9d0848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Dinov2ForImageClassification were not initialized from the model checkpoint at facebook/dinov2-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/dinov2-base\"\n",
    "dataset_name = \"temp_dataset_subsample\"\n",
    "\n",
    "model, image_datasets, _ = image_model_setup(model_name, dataset_name, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a8f934c-c915-46c0-80b8-dca0004660b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff60824195943e990aa9137d17fa590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0121 21:35:18.754000 34520 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 21:35:18.820000 34521 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 21:35:18.965000 34522 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 21:35:18.966000 34523 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "/Users/luke/.local/defaultPythonEnv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "/Users/luke/.local/defaultPythonEnv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c8b44b70c54498b4b58b0abdf50bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef331aed61c947a7a328fbcbb05e57f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0121 22:03:03.825000 34848 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 22:03:03.825000 34846 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 22:03:03.825000 34847 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 22:03:03.825000 34849 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15815efefca247de9dee7d2bc24d48fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/18 shards):   0%|          | 0/200000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14699df652440a4a62b58e17ebe2651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/5 shards):   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7465de26fcc0411f9a96fb1382745178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "activity_dataset = generate_activity_dataset(model, image_datasets,\n",
    "                                             include_classifier_inputs=True,\n",
    "                                             output_dir='temp_activity_dataset',\n",
    "                                             device='mps'\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303f9321-042d-4fea-91d0-f268d5e8f363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<setup.ModelWrapper at 0x1348208c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_probes_by_ridge_regression(model, activity_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "607157d6-72a7-469f-816a-1a73c4762593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]W0121 22:14:21.476000 35035 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 22:14:21.476000 35032 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 22:14:21.476000 35034 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 22:14:21.476000 35033 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "338it [06:13,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [07:14,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [07:15,  1.11s/it]\n",
      "0it [00:00, ?it/s]W0121 22:21:37.080000 35151 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 22:21:37.080000 35153 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 22:21:37.081000 35154 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 22:21:37.082000 35152 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "338it [06:27,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [07:28,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [07:28,  1.15s/it]\n",
      "0it [00:00, ?it/s]W0121 22:29:05.838000 35256 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 22:29:05.860000 35253 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 22:29:05.866000 35255 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0121 22:29:05.867000 35254 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "338it [06:31,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [07:32,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [07:33,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "acc = model_accuracy(model.model, image_datasets['test'], shuffle=None, device='mps', num_workers=4)\n",
    "\n",
    "with model.zero_out_auxiliary_outputs():\n",
    "    acc_no_GAP = model_accuracy(model.model, image_datasets['test'], shuffle=None, device='mps', num_workers=4)\n",
    "\n",
    "acc_post = model_accuracy(model.model, image_datasets['test'], shuffle=None, device='mps', num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31cc34e-3663-4565-8423-ca6d43318b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7628399729728699 0.7245200276374817 0.7628399729728699\n"
     ]
    }
   ],
   "source": [
    "print(acc, acc_no_GAP, acc_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fd4f3d6-ffcf-4192-acac-68cf638b8052",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "probe_results = linear_probe_by_ridge_regression(activity_dataset, cvfold=5)\n",
    "all_results.append(probe_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2851125-a8fe-47ef-ace2-b749842ae38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“• Analysis: <function accuracy_random_CLS at 0x33cbb9da0>\n",
      "ðŸ“„ Layer: dinov2.encoder.layer.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:51,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:27,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:17,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:14,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:15,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:15,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:15,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:14,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:15,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:15,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:16,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:15,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "randomization_results = run_across_layers(model, image_datasets,\n",
    "                                          accuracy_random_CLS,  shuffle=None,\n",
    "                                          device='mps')\n",
    "all_results.append(randomization_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2979139-6339-4578-9a5f-4d00aa107d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“• Analysis: <function accuracy_random_CLS at 0x33cbb9da0>\n",
      "ðŸ“„ Layer: dinov2.encoder.layer.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:15,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:16,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:16,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:16,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:16,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:17,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:16,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:16,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:16,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:16,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:16,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: dinov2.encoder.layer.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [09:16,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "with model.zero_out_auxiliary_outputs():\n",
    "    randomization_results = run_across_layers(model, image_datasets,\n",
    "                                              accuracy_random_CLS,  shuffle=None,\n",
    "                                              device='mps')\n",
    "\n",
    "randomization_results['GAP_disabled'] = True\n",
    "all_results.append(randomization_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "566b20a4-9626-4a7b-b643-a010a96c6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(all_results).to_csv('results/cross_model_CLS/results_dino.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eedc96-d6f6-4151-87ac-a8591395d39d",
   "metadata": {},
   "source": [
    "### Beit\n",
    "\n",
    "We need to properly configure the model to use CLS tokens rather than mean pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a46a0ce-34ff-4073-94bd-d2c4143ba721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d446e0a8ab4bcb9f9df108821b7bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/beit-base-patch16-224-pt22k-ft22k were not used when initializing BeitForImageClassification: ['beit.pooler.layernorm.bias', 'beit.pooler.layernorm.weight']\n",
      "- This IS expected if you are initializing BeitForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BeitForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BeitForImageClassification were not initialized from the model checkpoint at microsoft/beit-base-patch16-224-pt22k-ft22k and are newly initialized: ['beit.layernorm.bias', 'beit.layernorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BeitForImageClassification were not initialized from the model checkpoint at microsoft/beit-base-patch16-224-pt22k-ft22k and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([21841, 768]) in the checkpoint and torch.Size([1000, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([21841]) in the checkpoint and torch.Size([1000]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/beit-base-patch16-224-pt22k-ft22k\"\n",
    "dataset_name = \"temp_dataset_subsample\"\n",
    "\n",
    "model, image_datasets, _ = image_model_setup(model_name, dataset_name, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15bbd1da-2d8b-4af1-99c3-95bfdff47097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa69115666f34299ad9245ab7fb88335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0122 09:12:54.079000 39518 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0122 09:12:54.084000 39517 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0122 09:12:54.087000 39520 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0122 09:12:54.101000 39519 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "/Users/luke/.local/defaultPythonEnv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "/Users/luke/.local/defaultPythonEnv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4388a4ca03894548bc6ba45e67cd09a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0122 09:37:20.784000 39793 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0122 09:37:20.784000 39791 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0122 09:37:20.784000 39792 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0122 09:37:20.784000 39794 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01080931d38641b29a9b94d3cfd55de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/16 shards):   0%|          | 0/200000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f33e8190cc646ef823b6d5cd7c48a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "activity_dataset = generate_activity_dataset(model, image_datasets,\n",
    "                                             include_classifier_inputs=True,\n",
    "                                             output_dir='temp_activity_dataset',\n",
    "                                             device='mps'\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bb9fa07-a7c5-4097-b46a-4c2710618d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<setup.ModelWrapper at 0x31990bec0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_probes_by_ridge_regression(model, activity_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a88008a7-af59-484d-88dd-8dee3fa39a28",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]W0122 09:46:44.251000 39893 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0122 09:46:44.259000 39892 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0122 09:46:44.264000 39894 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0122 09:46:44.264000 39891 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "338it [04:52,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [05:38,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n",
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [05:39,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "acc = model_accuracy(model.model, image_datasets['test'], shuffle=None, device='mps', num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d63659b-9f53-48ec-b2f9-3e58ae3639a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7053999900817871\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2424df8c-af9b-4cf9-b626-0c942b2a8450",
   "metadata": {},
   "source": [
    "Good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c6bc0b5-619c-44be-a0bc-da1926d317b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "probe_results = linear_probe_by_ridge_regression(activity_dataset, cvfold=5)\n",
    "all_results.append(probe_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "784838d5-deb0-4f28-9cf6-5097f731f267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“• Analysis: <function accuracy_random_CLS at 0x31aab5f80>\n",
      "ðŸ“„ Layer: beit.encoder.layer.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:46,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: beit.encoder.layer.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:25,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: beit.encoder.layer.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:30,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: beit.encoder.layer.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:28,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: beit.encoder.layer.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:29,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: beit.encoder.layer.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:28,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: beit.encoder.layer.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:28,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: beit.encoder.layer.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:26,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: beit.encoder.layer.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:26,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: beit.encoder.layer.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:25,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: beit.encoder.layer.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:24,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Layer: beit.encoder.layer.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [07:24,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "randomization_results = run_across_layers(model, image_datasets,\n",
    "                                          accuracy_random_CLS,  shuffle=None,\n",
    "                                          device='mps')\n",
    "all_results.append(randomization_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56f13bc1-adce-4412-8521-4d63b5369a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                    layer  accuracy             test\n",
       " 0    beit.encoder.layer.0   0.01224  layerwise_probe\n",
       " 1    beit.encoder.layer.1   0.08510  layerwise_probe\n",
       " 2    beit.encoder.layer.2   0.11900  layerwise_probe\n",
       " 3    beit.encoder.layer.3   0.15024  layerwise_probe\n",
       " 4    beit.encoder.layer.4   0.20848  layerwise_probe\n",
       " 5    beit.encoder.layer.5   0.23442  layerwise_probe\n",
       " 6    beit.encoder.layer.6   0.30842  layerwise_probe\n",
       " 7    beit.encoder.layer.7   0.37152  layerwise_probe\n",
       " 8    beit.encoder.layer.8   0.42894  layerwise_probe\n",
       " 9    beit.encoder.layer.9   0.49438  layerwise_probe\n",
       " 10  beit.encoder.layer.10   0.56520  layerwise_probe\n",
       " 11  beit.encoder.layer.11   0.71438  layerwise_probe\n",
       " 12      classifier_inputs   0.70898  layerwise_probe,\n",
       "                     layer  accuracy               test\n",
       " 0    beit.encoder.layer.0   0.70554  cls_randomization\n",
       " 1    beit.encoder.layer.1   0.70510  cls_randomization\n",
       " 2    beit.encoder.layer.2   0.70504  cls_randomization\n",
       " 3    beit.encoder.layer.3   0.70502  cls_randomization\n",
       " 4    beit.encoder.layer.4   0.70518  cls_randomization\n",
       " 5    beit.encoder.layer.5   0.70514  cls_randomization\n",
       " 6    beit.encoder.layer.6   0.70424  cls_randomization\n",
       " 7    beit.encoder.layer.7   0.69996  cls_randomization\n",
       " 8    beit.encoder.layer.8   0.68586  cls_randomization\n",
       " 9    beit.encoder.layer.9   0.63926  cls_randomization\n",
       " 10  beit.encoder.layer.10   0.63304  cls_randomization\n",
       " 11  beit.encoder.layer.11   0.00626  cls_randomization]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64458645-b20e-4a4c-97b1-5c30c71c5987",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(all_results).to_csv('results/cross_model_CLS/results_beit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b63c0-5994-48ef-9ba5-853844b7b244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a105499-987b-43b6-b004-44bcf9170a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c339f88-923a-407c-bfb1-d9f7e8cacfc5",
   "metadata": {},
   "source": [
    "### openai/clip-vit-base-patch32\n",
    "\n",
    "The previous results are sufficient for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d291e-32af-4ddf-a18d-3742468448ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
