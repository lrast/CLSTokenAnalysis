{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "935b5721-30f1-432a-9052-6ceea24e9afe",
   "metadata": {},
   "source": [
    "# Testing different readout methods in the few-shot context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d96efda5-0c88-4dba-b209-29fcbf9d2647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.environ[\"HF_DATASETS_DISABLE_PROGRESS_BAR\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a4157c-5bef-4295-8179-4bbda0ca518f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "def load_cdfsl_dataset(name):\n",
    "    \"\"\"\n",
    "    Loads CD-FSL datasets using the most stable configurations \n",
    "    to avoid legacy script and config errors.\n",
    "    \"\"\"\n",
    "    match name:\n",
    "        case \"EuroSAT\":\n",
    "            return load_dataset(\"timm/eurosat-rgb\", split=\"train\")\n",
    "        \n",
    "        case \"ISIC\":\n",
    "            return load_dataset(\"marmal88/skin_cancer\", split=\"train\")\n",
    "        \n",
    "        case \"PlantVillage\":\n",
    "            return load_dataset(\"mohanty/PlantVillage\", \"default\", split=\"train\")\n",
    "        \n",
    "        case \"ChestX\":\n",
    "            return load_dataset(\"g-ronimo/NIH-Chest-X-ray-dataset_10k\",  split=\"train\")\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown dataset: {name}\")\n",
    "\n",
    "\n",
    "def n_way_k_shot_sample(ds, k, seed=None):\n",
    "    \"\"\"n-way k-shot subsample from the dataset\"\"\"\n",
    "    if seed is not None:\n",
    "        raise NotImplementedError('No seeding')\n",
    "    labels = torch.tensor(ds['label']).unique()\n",
    "\n",
    "    counts_remaining = {label.item(): k for label in labels}\n",
    "    \n",
    "    perms = torch.randperm( len(ds))\n",
    "    inds = []\n",
    "\n",
    "    for index in perms:\n",
    "        if sum(counts_remaining.values()) <= 0:\n",
    "            break\n",
    "\n",
    "        label = ds[index.item()]['label']\n",
    "        if counts_remaining[label] > 0:\n",
    "            counts_remaining[label] -= 1\n",
    "            inds.append(index)\n",
    "\n",
    "    return ds.select(inds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce061679-ed0d-478c-be49-36f945e094ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0217 14:45:24.041000 9762 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "from src.model.setup import image_model_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e5784b7-6ca8-451c-939f-7971d6485e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Dinov2ForImageClassification were not initialized from the model checkpoint at facebook/dinov2-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/dinov2-base\"\n",
    "ds_raw = load_cdfsl_dataset( \"EuroSAT\")\n",
    "\n",
    "\n",
    "model, ds, _ = image_model_setup(model_name, '', 10, full_dataset=ds_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc5f00c6-e72b-4da0-9892-d318200fcc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_subset = n_way_k_shot_sample(ds, 5)\n",
    "ds_subset.set_format('pt')\n",
    "\n",
    "ds.set_format('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25245ca7-c282-4d5e-a71f-f8a92280932b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "def accuracy(model, ds):\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    \n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "    eval_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        per_device_eval_batch_size=64,\n",
    "        do_train=False,\n",
    "        do_eval=True,\n",
    "        report_to=\"none\", # Keeps it quiet\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=eval_args,\n",
    "        eval_dataset=ds.rename_columns({'input': 'pixel_values'}), # Your tensor-ready dataset\n",
    "        compute_metrics=compute_metrics,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    results = trainer.evaluate()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d67a27-8fad-40a6-95df-0a82716c47b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a17193-17b3-4d43-91a8-87a5be783639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke/.local/defaultPythonEnv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [254/254 02:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = accuracy(model.model, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9038a70-e25d-4d1d-a80a-57e94cd87e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_loss'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2079784870147705</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_model_preparation_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0012</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.10746913580246914</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_runtime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">170.4022</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_samples_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">95.069</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_steps_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.491</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'eval_loss'\u001b[0m: \u001b[1;36m3.2079784870147705\u001b[0m,\n",
       "    \u001b[32m'eval_model_preparation_time'\u001b[0m: \u001b[1;36m0.0012\u001b[0m,\n",
       "    \u001b[32m'eval_accuracy'\u001b[0m: \u001b[1;36m0.10746913580246914\u001b[0m,\n",
       "    \u001b[32m'eval_runtime'\u001b[0m: \u001b[1;36m170.4022\u001b[0m,\n",
       "    \u001b[32m'eval_samples_per_second'\u001b[0m: \u001b[1;36m95.069\u001b[0m,\n",
       "    \u001b[32m'eval_steps_per_second'\u001b[0m: \u001b[1;36m1.491\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9bae2-2eae-4c16-9cb6-9ef6caea63ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247c47f9-d680-4374-bd41-7da842a8fae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f428ecb-50df-4c19-bbfa-5629e5c08f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
