{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8abf01-7445-4b09-b55a-672f91c9b750",
   "metadata": {},
   "source": [
    "# Container script for pilot training:\n",
    "\n",
    "Using deterministic CLS tokens\n",
    "\n",
    "Notes:\n",
    "- ran multiple runs of layer 10 due to saving errors. They look different, probably because of random initialization of the (deterministic) CLS generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e19049cb-2944-4220-acb0-261bc5be4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "from src.model.setup import image_model_setup\n",
    "from src.data.activity_dataset import OnlineLayerInputDataset\n",
    "from src.model.CLS_token_probing import ModuleSpecificDecoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d52396d9-1676-49db-b378-3774773bcdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'replace'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a29eb6-c138-4377-acf8-507016b527da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42705095aadd40b1a6fb10cd2edee1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/223 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mDinov2ForImageClassification LOAD REPORT\u001b[0m from: facebook/dinov2-base\n",
      "Key               | Status  | \n",
      "------------------+---------+-\n",
      "classifier.weight | MISSING | \n",
      "classifier.bias   | MISSING | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb7d3ad75304d75a374b4cd69943adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/223 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mDinov2ForImageClassification LOAD REPORT\u001b[0m from: facebook/dinov2-base\n",
      "Key               | Status  | \n",
      "------------------+---------+-\n",
      "classifier.weight | MISSING | \n",
      "classifier.bias   | MISSING | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dinov2ForImageClassification(\n",
       "  (dinov2): Dinov2Model(\n",
       "    (embeddings): Dinov2Embeddings(\n",
       "      (patch_embeddings): Dinov2PatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Dinov2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x Dinov2Layer(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attention): Dinov2Attention(\n",
       "            (attention): Dinov2SelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): Dinov2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (layer_scale1): Dinov2LayerScale()\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Dinov2MLP(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_scale2): Dinov2LayerScale()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1536, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "model_name = \"facebook/dinov2-base\"\n",
    "dataset_name = \"../workspace/temp_dataset_subsample\"\n",
    "\n",
    "# model for train data generate\n",
    "model, image_datasets, _ = image_model_setup(model_name, dataset_name, 1000)\n",
    "\n",
    "# second copy of the model: used for e\n",
    "model_analysis, _, _ = image_model_setup(model_name, dataset_name, 1000)\n",
    "model_analysis.to(device)\n",
    "model_analysis.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b68adf1a-f357-4167-b430-ccfe67584038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.CLS_token_probing import DeterministicCLSGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19838c5d-6030-482e-b96a-9fa50355a05a",
   "metadata": {},
   "source": [
    "The previous training script doesn't work with modules that can have configurable sub-modules. Quick hack to accomplish this in the pilot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24c9bdb9-120a-42bd-a997-1722f52c5634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "\n",
    "def train_module_decoder(decoder_model, base_modules,\n",
    "                         train_dataloader, val_dataloader,\n",
    "                         max_epochs=5, patience=5,\n",
    "                         accelerator=\"auto\", devices=\"auto\",\n",
    "                         **trainer_kwargs):\n",
    "    \"\"\"\n",
    "    Trains a ModuleSpecificDecoder using pytorch_lightning. Early stops on validation loss.\n",
    "    Loads the best model weights at the end.\n",
    "\n",
    "    Args:\n",
    "        decoder_model: An ModuleSpecificDecoder instance\n",
    "        base_modules: The modules that are being decoded\n",
    "        train_dataloader: PyTorch DataLoader for training set.\n",
    "        val_dataloader: PyTorch DataLoader for validation set.\n",
    "        max_epochs: Maximum epochs to train.\n",
    "        patience: Patience for early stopping on val_loss.\n",
    "        accelerator: Accelerator for training (\"cpu\", \"gpu\", \"auto\", etc.).\n",
    "        devices: Devices specification (\"auto\", int, etc.).\n",
    "        **trainer_kwargs: Additional kwargs for Trainer.\n",
    "    Returns:\n",
    "        Trained (best weights) model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Early stopping on validation loss\n",
    "    early_stop_cb = EarlyStopping(\n",
    "        monitor=\"val/accuracy\",\n",
    "        patience=patience,\n",
    "        verbose=True,\n",
    "        mode=\"max\"\n",
    "    )\n",
    "\n",
    "    # ModelCheckpoint to save the best model\n",
    "    checkpoint_cb = ModelCheckpoint(\n",
    "        monitor=\"val/accuracy\",\n",
    "        save_top_k=1,\n",
    "        mode=\"max\",\n",
    "        save_last=True,\n",
    "        filename=\"best\"\n",
    "    )\n",
    "\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "    wandb_logger = WandbLogger(project=\"middle_decoders\", log_model=True)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[early_stop_cb, checkpoint_cb, lr_monitor],\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        **trainer_kwargs,\n",
    "    )\n",
    "\n",
    "    trainer_model = TrainingWrapper_Decoder(decoder_model, base_modules, num_epochs=max_epochs)\n",
    "\n",
    "    trainer.fit(trainer_model, train_dataloader, val_dataloader)\n",
    "\n",
    "    # Load the best checkpoint, if available\n",
    "    best_model_path = checkpoint_cb.best_model_path\n",
    "    if best_model_path:\n",
    "        decoder_model = type(decoder_model).load_from_checkpoint(best_model_path, generator_class=DeterministicCLSGenerator)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    return decoder_model\n",
    "\n",
    "\n",
    "class TrainingWrapper_Decoder(pl.LightningModule):\n",
    "    \"\"\"Surrogate Module to use for training the Module decoders \n",
    "\n",
    "        Manages base_module dependence, training hyperparameters\n",
    "    \"\"\"\n",
    "    def __init__(self, decoder=None, base_modules=None, lr=1E-3, num_epochs=3):\n",
    "        super().__init__()\n",
    "        self.decoder = decoder\n",
    "        self.base_modules = base_modules\n",
    "        self.lr = lr\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "        # Are we decoding single layers or multiple layers?\n",
    "        self.multiple_decoder = isinstance(base_modules, dict)\n",
    "\n",
    "        if self.multiple_decoder:\n",
    "            to_freeze = self.base_modules.values()\n",
    "        else:\n",
    "            to_freeze = [self.base_modules]\n",
    "\n",
    "        # freeze the parameters of the base module\n",
    "        for module in to_freeze:\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            module.eval()\n",
    "\n",
    "    def forward(self, input_tokens):\n",
    "        if not self.multiple_decoder:\n",
    "            # the module is a single decoder module\n",
    "            inputs = list(input_tokens.items())[0][1]\n",
    "            return self.decoder.forward(inputs, self.base_modules)\n",
    "        else:\n",
    "            input_module_pairs = {key: (input_tokens[key], self.base_modules[key])\n",
    "                                  for key in self.base_modules.keys()\n",
    "                                  }\n",
    "            return self.decoder.forward(input_module_pairs)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Assumes batch = (input_tokens, targets)\n",
    "        - input_tokens: (B, L, D) float tensor\n",
    "        - targets: (B,) class indices\n",
    "        \"\"\"\n",
    "        targets = batch.pop('label')\n",
    "        input_tokens = batch\n",
    "\n",
    "        logits = self.forward(input_tokens)\n",
    "        loss = self.decoder.loss_fn(logits, targets)\n",
    "\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        targets = batch.pop('label')\n",
    "        input_tokens = batch\n",
    "\n",
    "        logits = self.forward(input_tokens)\n",
    "        loss = self.decoder.loss_fn(logits, targets)\n",
    "        acc = (logits.argmax(-1) == targets).float().mean()\n",
    "        self.log(\"val/loss\", loss, prog_bar=True)\n",
    "        self.log(\"val/accuracy\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        # T_max is the number of epochs to reach the minimum LR\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=self.num_epochs*3125, eta_min=1e-6)\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def on_save_checkpoint(self, checkpoint):\n",
    "        \"\"\" Strip the base_module weights from the checkpoint \"\"\"\n",
    "        checkpoint['state_dict'] = self.decoder.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a8931-35ac-44c6-a47e-935ac39ffbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c04afa-5413-4303-9c2b-cef5274626cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The anonymous setting has no effect and will be removed in a future version.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from WANDB_API_KEY.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlrast\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.25.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>wandb/run-20260216_202346-z6rk0skl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lrast/middle_decoders/runs/z6rk0skl' target=\"_blank\">deep-armadillo-114</a></strong> to <a href='https://wandb.ai/lrast/middle_decoders' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lrast/middle_decoders' target=\"_blank\">https://wandb.ai/lrast/middle_decoders</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lrast/middle_decoders/runs/z6rk0skl' target=\"_blank\">https://wandb.ai/lrast/middle_decoders/runs/z6rk0skl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name         </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ decoder      â”‚ ModuleSpecificDecoder â”‚  769 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ base_modules â”‚ Dinov2Layer           â”‚  7.1 M â”‚ eval  â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName        \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType                 \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ decoder      â”‚ ModuleSpecificDecoder â”‚  769 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ base_modules â”‚ Dinov2Layer           â”‚  7.1 M â”‚ eval  â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 769 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 7.1 M                                                                                        \n",
       "<span style=\"font-weight: bold\">Total params</span>: 7.9 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 31                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 4                                                                                           \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 18                                                                                           \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 769 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 7.1 M                                                                                        \n",
       "\u001b[1mTotal params\u001b[0m: 7.9 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 31                                                                         \n",
       "\u001b[1mModules in train mode\u001b[0m: 4                                                                                           \n",
       "\u001b[1mModules in eval mode\u001b[0m: 18                                                                                           \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900989b2cf5c46c1b3eb83fff7acacd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py:534: Found 18 module(s) in eval mode at\n",
       "the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore\n",
       "this warning.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py:534: Found 18 module(s) in eval mode at\n",
       "the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore\n",
       "this warning.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to \n",
       "read 2 bytes but only got 0. \n",
       "  warnings.warn(str(msg))\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to \n",
       "read 2 bytes but only got 0. \n",
       "  warnings.warn(str(msg))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved. New best score: 0.686\n",
      "Metric val/accuracy improved by 0.051 >= min_delta = 0.0. New best score: 0.738\n",
      "Metric val/accuracy improved by 0.020 >= min_delta = 0.0. New best score: 0.758\n",
      "Metric val/accuracy improved by 0.011 >= min_delta = 0.0. New best score: 0.769\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Metric val/accuracy improved by 0.004 >= min_delta = 0.0. New best score: 0.773\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/lightning_fabric/utilities/cloud_io.py:73: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>lr-Adam</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–‡â–‡â–„â–„â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>trainer/global_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>val/accuracy</td><td>â–â–…â–‡â–ˆâ–ˆ</td></tr><tr><td>val/loss</td><td>â–ˆâ–„â–‚â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>lr-Adam</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.59645</td></tr><tr><td>trainer/global_step</td><td>15624</td></tr><tr><td>val/accuracy</td><td>0.77288</td></tr><tr><td>val/loss</td><td>0.92449</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deep-armadillo-114</strong> at: <a href='https://wandb.ai/lrast/middle_decoders/runs/z6rk0skl' target=\"_blank\">https://wandb.ai/lrast/middle_decoders/runs/z6rk0skl</a><br> View project at: <a href='https://wandb.ai/lrast/middle_decoders' target=\"_blank\">https://wandb.ai/lrast/middle_decoders</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>wandb/run-20260216_202346-z6rk0skl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 10\n",
    "\n",
    "layer_name = f'dinov2.encoder.layer.{i}'\n",
    "\n",
    "ds_train = OnlineLayerInputDataset(model, layer_name, image_datasets['train'],\n",
    "                               device=device)\n",
    "ds_validation = OnlineLayerInputDataset(model, layer_name, image_datasets['validation'],\n",
    "                                    device=device)\n",
    "\n",
    "probe = ModuleSpecificDecoder(mode=mode, generator_class=DeterministicCLSGenerator)\n",
    "base_module = model_analysis.module_dict[layer_name]\n",
    "model_out = train_module_decoder(probe, base_module, ds_train, ds_validation)\n",
    "model_out.save_pretrained(f'outs_{mode}/layer{i}_probe_{mode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b41b0aa-d435-49db-bc24-9094934936db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f71bb-02e3-4a28-86d1-384b525f750f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The anonymous setting has no effect and will be removed in a future version.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from WANDB_API_KEY.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlrast\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.25.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>wandb/run-20260217_004322-f9tfmles</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lrast/middle_decoders/runs/f9tfmles' target=\"_blank\">spring-armadillo-116</a></strong> to <a href='https://wandb.ai/lrast/middle_decoders' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lrast/middle_decoders' target=\"_blank\">https://wandb.ai/lrast/middle_decoders</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lrast/middle_decoders/runs/f9tfmles' target=\"_blank\">https://wandb.ai/lrast/middle_decoders/runs/f9tfmles</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name         </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ decoder      â”‚ ModuleSpecificDecoder â”‚  769 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ base_modules â”‚ Dinov2Layer           â”‚  7.1 M â”‚ eval  â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName        \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType                 \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ decoder      â”‚ ModuleSpecificDecoder â”‚  769 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ base_modules â”‚ Dinov2Layer           â”‚  7.1 M â”‚ eval  â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 769 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 7.1 M                                                                                        \n",
       "<span style=\"font-weight: bold\">Total params</span>: 7.9 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 31                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 4                                                                                           \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 18                                                                                           \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 769 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 7.1 M                                                                                        \n",
       "\u001b[1mTotal params\u001b[0m: 7.9 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 31                                                                         \n",
       "\u001b[1mModules in train mode\u001b[0m: 4                                                                                           \n",
       "\u001b[1mModules in eval mode\u001b[0m: 18                                                                                           \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfd198bf7524d6aafeea5f1b8e36050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py:534: Found 18 module(s) in eval mode at\n",
       "the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore\n",
       "this warning.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py:534: Found 18 module(s) in eval mode at\n",
       "the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore\n",
       "this warning.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to \n",
       "read 2 bytes but only got 0. \n",
       "  warnings.warn(str(msg))\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to \n",
       "read 2 bytes but only got 0. \n",
       "  warnings.warn(str(msg))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved. New best score: 0.444\n",
      "Metric val/accuracy improved by 0.115 >= min_delta = 0.0. New best score: 0.558\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Metric val/accuracy improved by 0.040 >= min_delta = 0.0. New best score: 0.599\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layer_inds = [8, 9, 11]\n",
    "\n",
    "for i in layer_inds:\n",
    "    layer_name = f'dinov2.encoder.layer.{i}'\n",
    "\n",
    "    ds_train = OnlineLayerInputDataset(model, layer_name, image_datasets['train'],\n",
    "                                       device=device)\n",
    "    ds_validation = OnlineLayerInputDataset(model, layer_name, image_datasets['validation'],\n",
    "                                            device=device)\n",
    "\n",
    "    probe = ModuleSpecificDecoder(mode=mode, generator_class=DeterministicCLSGenerator)\n",
    "\n",
    "    base_module = model_analysis.module_dict[layer_name]\n",
    "\n",
    "    model_out = train_module_decoder(probe, base_module, ds_train, ds_validation)\n",
    "    model_out.save_pretrained(f'outs_{mode}/layer{i}_probe_{mode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f524dd-361e-4742-bd21-c62b4f146704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ef489-c35c-45c2-92b8-0f950a8ff358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
